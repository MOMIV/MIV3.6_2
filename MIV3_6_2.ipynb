{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85S5lVQcVi7A",
        "outputId": "2df4713d-1e04-47d0-f66b-a2624e24f830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puV1otZUkRtu",
        "outputId": "e1fdd83b-2c80-422c-8337-4840bf279fd8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.10/dist-packages (30.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from faker) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField,StringType, IntegerType, FloatType, DateType\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import datetime\n",
        "from dateutil.relativedelta import relativedelta"
      ],
      "metadata": {
        "id": "V0IQns4mVpqO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание SparkSession\n",
        "spark = SparkSession.builder \\\n",
        ".appName(\"SparkDataGnrt\") \\\n",
        ".getOrCreate()"
      ],
      "metadata": {
        "id": "6IOx5n9wVptN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_create(num):\n",
        "  fake = Faker(\"ru_RU\")\n",
        "  end_date = datetime.date.today()\n",
        "  st_date = end_date - relativedelta(years=1)\n",
        "  data = []\n",
        "  for _ in range(num):\n",
        "    data.append({\n",
        "        'date': fake.date_between(st_date, end_date),\n",
        "        'user_id': fake.uuid4(),\n",
        "        'product': fake.random_element(['food', 'medicines', 'cosmetics', 'clothes', 'instrument']),\n",
        "        'quantity': random.randint(1, 100),\n",
        "        'price': random.uniform(10, 1000),\n",
        "\n",
        "    })\n",
        "  df = pd.DataFrame(data)\n",
        "  return df"
      ],
      "metadata": {
        "id": "6yQoYRPwVpwa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определяем структуру данных\n",
        "my_schema = StructType([\n",
        "StructField(\"date\", DateType(), True),\n",
        "StructField(\"user_id\", StringType(), True),\n",
        "StructField(\"product\", StringType(), True),\n",
        "StructField(\"quantity\", IntegerType(), True),\n",
        "StructField(\"price\", FloatType(), True)                         ])"
      ],
      "metadata": {
        "id": "Nhp3ot-5WFzl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание DataFrame\n",
        "df_spark = spark.createDataFrame(df_create(1000), schema= my_schema)\n"
      ],
      "metadata": {
        "id": "dw4nIEewWF2q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark = df_spark.repartition(1)\n",
        "df_spark.write.option(\"header\",True) \\\n",
        " .csv(\"/Загрузки/df_spark\")"
      ],
      "metadata": {
        "id": "FgRDtswcVpza"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Закрытие SparkSession\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "0U7gA7nPVp2J"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}